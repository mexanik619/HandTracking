{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose a mode:\n",
      "1 - Hand Tracking (Webcam)\n",
      "2 - Image Recognition (Static Image)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter 1 or 2:  1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# ---------------------- Hand Tracking ---------------------- #\n",
    "def handtrack():\n",
    "    mp_hands = mp.solutions.hands\n",
    "    hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.7)\n",
    "    mp_draw = mp.solutions.drawing_utils\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    def is_open_hand(landmarks):\n",
    "        tips_ids = [4, 8, 12, 16, 20]  # Thumb, Index, Middle, Ring, Pinky tips\n",
    "        open_count = 0\n",
    "        for tip in tips_ids[1:]:  # Skipping thumb for now\n",
    "            if landmarks[tip].y < landmarks[tip - 2].y:  # Check if finger is extended\n",
    "                open_count += 1\n",
    "        return open_count >= 4\n",
    "\n",
    "    def is_punch(landmarks):\n",
    "        tips_ids = [8, 12, 16, 20]\n",
    "        return all(abs(landmarks[tip].y - landmarks[0].y) < 0.05 for tip in tips_ids)\n",
    "\n",
    "    while True:\n",
    "        success, img = cap.read()\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(img_rgb)\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_draw.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                lm_list = hand_landmarks.landmark\n",
    "\n",
    "                if is_open_hand(lm_list):\n",
    "                    cv2.putText(img, \"Open Hand 🖐️\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "                elif is_punch(lm_list):\n",
    "                    cv2.putText(img, \"Punch ✊\", (10, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imshow(\"Hand Tracking + Gesture\", img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "# ---------------------- Image Recognition ---------------------- #\n",
    "def imgrecognition():\n",
    "    model = MobileNetV2(weights='imagenet')\n",
    "\n",
    "    img_path = 'myimage.png'  # Replace with your image filename\n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"[ERROR] Image file '{img_path}' not found.\")\n",
    "        return\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "    decoded = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "    print(\"Top Predictions:\")\n",
    "    for i, (imagenetID, label, prob) in enumerate(decoded):\n",
    "        print(f\"{i+1}. {label}: {prob*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------- Main ---------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Choose a mode:\")\n",
    "    print(\"1 - Hand Tracking (Webcam)\")\n",
    "    print(\"2 - Image Recognition (Static Image)\")\n",
    "\n",
    "    choice = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "    if choice == '1':\n",
    "        handtrack()\n",
    "    elif choice == '2':\n",
    "        imgrecognition()\n",
    "    else:\n",
    "        print(\"Invalid input. Please enter 1 or 2.\")\n",
    "        \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
